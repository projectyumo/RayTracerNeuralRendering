{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d9da804b-38c4-426f-b8fd-0684d1971673",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "eeb6239",
    "execution_start": 1650752472958,
    "execution_millis": 1062,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585
   },
   "source": "import json\nimport numpy as np\nimport time\nfrom PIL import Image\nimport math\nimport matplotlib.pyplot as plt\nimport random\nimport uuid\nimport pandas as pd\n\ndef f01(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x0*y1)-(x1*y0)\n    u = y0-y1\n    v = x1-x0\n    \n    return ((u*x) + (v*y) + q)/((u*x2) + (v*y2) + q)\n\ndef f12(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x1*y2)-(x2*y1)\n    u = y1-y2\n    v = x2-x1\n    \n    return ((u*x) + (v*y) + q)/((u*x0) + (v*y0) + q)\n\ndef f20(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x2*y0)-(x0*y2)\n    u = y2-y0\n    v = x0-x2\n    return ((u*x) + (v*y) + q)/((u*x1) + (v*y1) + q)",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Direction: P2-P1 (128, 100, -1) - (0, 0, 0) = (128, 100, -1)\n# Normalize the above\nclass LightSource:\n    def __init__(self, color, intensity, l_type, p=None):\n        self.p = p\n        self.color = color\n        self.intensity = intensity\n        self.l_type = l_type\n    \n# Lighting Model to get ADS \nclass Lighting:\n    def __init__(self,\n                 camera,\n                 ambient_light,\n                 directional_light\n                ):\n        self.L = self.normalize(directional_light.p) # TODO: include from-to explicitly incase data is different in future\n        self.V = camera.d\n        \n        # Ambient lighting parameters\n        self.aColor = np.array(ambient_light.color)\n        self.Ia = np.array(ambient_light.intensity)\n        \n        # Directional lighting parameters\n        self.dColor = np.array(directional_light.color) #Directional Color\n        self.Ie = directional_light.intensity\n        \n    def calculateADS(self, p, n, material):\n        n = self.normalize(n) #Normal Vector\n        v = self.normalize(self.V - np.array(p))\n        \n        # Cases that come up in shading...\n        if np.dot(n, self.L) < 0 and np.dot(n, v) < 0: n*=-1 # CASE 1: \n        elif np.dot(n, self.L) * np.dot(n, v) < 0: emissive = np.array([0,0,0])\n        \n        Ka, Kd, Ks = material['Ka'], material['Kd'], material['Ks']\n        S = material['n']\n        \n        a = self.ambient(Ka)\n        d = self.diffuse(Kd, n)\n        s = self.specular(Ks, n, v, S)\n        \n        return a+d+s\n            \n    def ambient(self, Ka):\n        return Ka * self.aColor * self.Ia\n    \n    def diffuse(self, Kd, n):\n        dotnl = np.dot(n, self.L)\n        dotnl = np.clip(dotnl, 0, 1)\n        return Kd * self.dColor * dotnl * self.Ie\n    \n    def specular(self, Ks, n, v, S):\n        r = self.reflectionVector(n)\n        \n        dotre = np.dot(r, v)\n        dotre = np.clip(dotre, 0, 1) # Clamp RE\n        dotre = dotre**S # Apply Shininess\n        return Ks * self.dColor * dotre * self.Ie\n    \n    def reflectionVector(self, n):\n        # Calculate Normalized Reflection Vector\n        r = 2*(np.dot(n, self.L))*n - self.L\n        return self.normalize(r)\n        \n    def normalize(self, pt): \n        l = math.sqrt(pt[0]**2 + pt[1]**2 + pt[2]**2)\n        return np.array([pt[0]/l, pt[1]/l, pt[2]/l])",
   "metadata": {
    "cell_id": "6c5bffc65e734f73b9f1bcdc5596f98a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4eca4aa7",
    "execution_start": 1650752474039,
    "execution_millis": 46,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1287
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "059dfa2aa5a246d5ad7f2aa1bdc0b174",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "45f4cdde",
    "execution_start": 1650752474101,
    "execution_millis": 10,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1413
   },
   "source": "class RenderTransforms:\n    def __init__(self):\n        # RST Matrix Placeholders\n        self.M = np.array([\n                            [1, 0, 0, 0],\n                            [0, 1, 0, 0],\n                            [0, 0, 1, 0],\n                            [0, 0, 0, 1]\n                        ])\n        self.M_inv = np.array([\n                            [1, 0, 0, 0],\n                            [0, 1, 0, 0],\n                            [0, 0, 1, 0],\n                            [0, 0, 0, 1]\n                        ])\n    \n    def composeM(self,transforms):\n        # Theta assumed in Degrees\n        thetax, thetay, thetaz = np.array([transforms[0]['Rx'], transforms[0]['Ry'], transforms[0]['Rz']])*math.pi/180\n        tx, ty, tz = transforms[2]['T']\n        sx, sy, sz = transforms[1]['S']\n        \n        trans_mat = self.constructTranslationMat(tx,ty,tz)\n        rot_mat = self.constructRotationMat(thetax,thetay,thetaz)\n        scale_mat = self.constructScaleMat(sx,sy,sz)\n        \n        self.M = np.matmul(np.matmul(trans_mat, rot_mat), scale_mat)\n        self.M_inv = np.matmul(np.matmul(trans_mat, rot_mat), np.linalg.inv(scale_mat))\n        \n        return self.M\n        \n    def constructRotationMat(self, theta_x, theta_y, theta_z):\n        XFORM_ROTX = np.array([\n                        [1, 0, 0, 0],\n                        [0, math.cos(theta_x), -math.sin(theta_x), 0],\n                        [0, math.sin(theta_x), math.cos(theta_x), 0 ],\n                        [0, 0, 0, 1]\n                     ])\n\n        XFORM_ROTY = np.array([\n                                [math.cos(theta_y), 0, math.sin(theta_y), 0],\n                                [0, 1, 0, 0],\n                                [-math.sin(theta_y), 0, math.cos(theta_y), 0],\n                                [0, 0, 0, 1],\n                             ])\n\n        XFORM_ROTZ = np.array([\n                                [math.cos(theta_z), -math.sin(theta_z), 0, 0],\n                                [math.sin(theta_z), math.cos(theta_z), 0, 0],\n                                [0, 0, 1, 0],\n                                [0, 0, 0, 1],\n                             ])\n        \n        rot_mat = np.matmul(XFORM_ROTX, XFORM_ROTY)\n        return np.matmul(rot_mat, XFORM_ROTZ)\n        \n    def constructScaleMat(self, sx, sy, sz):\n        return np.array([\n                            [sx, 0, 0, 0],\n                            [0, sy, 0, 0],\n                            [0, 0, sz, 0],\n                            [0, 0, 0, 1]\n                        ])\n    \n    def constructTranslationMat(self, tx, ty, tz):\n         return np.array([\n                             [1, 0, 0, tx],\n                             [0, 1, 0, ty],\n                             [0, 0, 1, tz],\n                             [0, 0, 0, 1]\n                        ])\n        \n    def RST(self, pt):\n        pt = np.array(pt+[1])\n        return np.matmul(self.M, pt)",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# RayTracer\nhttps://bytes.usc.edu/cs580/s22_CG-012-Ren/lectures/Lect_RT/GeomQueries/slides_intersections.html",
   "metadata": {
    "cell_id": "00001-05936431-f3ff-4bb0-8571-b1b4b3155b22",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 120.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1d23005ecb224de1a80441931219c1f9",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7a8f2b1",
    "execution_start": 1650752474128,
    "execution_millis": 33,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 3969
   },
   "source": "# Miscellaneous:\n#  Determine image plane given camera @ (0,0,0) with a Field-of-View and how to \n#    convert the image plane into a pixelated image. \n#    Let Field-of-View = 120 deg (matching iPhone 13)\n#  Create surface plane to show shadows from ray-tracing\n#  Calculate sphere model (pending)\n \n\n# Direction: P2-P1 (128, 100, -1) - (0, 0, 0) = (128, 100, -1)\n# Normalize the above\nclass Ray:\n    def __init__(self, p0, d, t = -1):\n        # p0, origin of a Ray\n        self.p0 = p0 \n        # Divide d by magnitude of d to normalize\n        self.d = d/np.sqrt(np.dot(d,d))\n        self.t = t\n        # d, unit vector, direction of ray (normalized)\n        # self.var = None\n    \n    def set_t(self, t):\n        self.t = t\n    \n    def get_point(self):\n        return np.add(self.p0, np.multiply(self.d, self.t))\n\nclass Plane:\n    def __init__(self, p0, normal):\n        self.p0 = p0 # point on the plane\n        self.normal = normal\n    \n    def on_plane(self, p1):\n        # Checks if point is on plane, not really useful but for reference\n        return (np.dot(normal, np.subtract(self.p0-p1)) == 0)\n\n\n# viewport of [1,1] and distance of 1 would make FOV 53 degrees\nclass RayTracer: \n    def __init__(self, obj_file, scene, lm, tm):        \n        self.viewport = scene.viewport\n        self.canvas = scene.canvas\n        self.camera = scene.camera\n        self.triangle = scene.camera\n        self.lightModel = lm\n        self.transformer = tm\n        \n        with open(obj_file) as jf:\n            data = json.load(jf)\n        self.triangles = data['data']\n        \n    def set_ray(self, d, p=None):\n        p0 = self.camera.p0\n        if p is not None: p0 = p \n            \n        self.ray = Ray(p0, d)\n        \n    def get_intersect(self, triangle):\n        # Calculate vectors\n        v0, v1, v2 = [triangle[v][\"v\"] for v in [\"v0\", \"v1\", \"v2\"]]\n        self.v0, self.v1, self.v2 = np.array(v0), np.array(v1), np.array(v2)\n        v10 = self.v1 - self.v0\n        v20 = self.v2 - self.v0\n        \n        # Get cross product of vectors \n        n = np.cross(v10, v20)\n        self.n = n / np.sqrt(np.dot(n, n))\n        d = -np.dot(self.n, self.v0)\n        \n        self.intersect = -(np.dot(self.n, self.ray.p0) + d)/np.dot(self.n, self.ray.d)\n        self.intersect_point = self.ray.d*self.intersect + self.ray.p0\n        return self.intersect\n    \n    def inTriangle(self):\n        # The normals for all 3 planes can be encoded in the identity matrix\n        plane_normals = np.identity(3)\n        # Check for planes perpendicular to the triangle\n        planes = np.matmul(plane_normals, self.n)\n        # Placeholder\n        projected_plane = 0 \n        # Select a valid plane to project to\n        for i in range(len(planes)): \n            if planes[i] != 0:\n                # Just leave loop once you found a valid plane\n                projected_plane = i\n                break\n        \n        # Projecting a point onto the x, y, or z plane can be thought of as just \n        # setting, x=0, y=0, or z=0 respectively\n        a,b = np.delete(self.intersect_point, projected_plane)\n        a0,b0 = np.delete(self.v0, projected_plane)\n        a1,b1 = np.delete(self.v1, projected_plane)\n        a2,b2 = np.delete(self.v2, projected_plane)\n        \n        # Calculate Barycentric Coordinates\n        self.alpha = f12(a,b,a0,b0,a1,b1,a2,b2)\n        self.beta  = f20(a,b,a0,b0,a1,b1,a2,b2)\n        self.gamma = f01(a,b,a0,b0,a1,b1,a2,b2)\n        \n        if (self.alpha >= 0) and (self.beta >= 0) and (self.gamma >= 0): return True\n        return False\n    \n    def castShadowRay(self, light_source, tm, triangles):\n        # Attempt to trace shadow ray back to light source \n        # If hits another poylgon, color should be a shadow\n        # If shadow ray can be traced back to light source, calculate lighting to fill pixel\n        \n        d = light_source.p - self.intersect_point\n        ray = Ray(ip, d)\n        raytracer.set_ray(d, ip)\n        \n        for triangle in triangles[::20]:\n            for v in [\"v0\", \"v1\", \"v2\"]: triangle[v][\"v\"] = list(tm.RST(triangle[v][\"v\"]))[:3]\n            n = np.array([triangle[v]['n'] for v in ['v0', 'v1', 'v2']])\n        \n            t = raytracer.get_intersect(triangle)\n            if t>0 and raytracer.inTriangle():\n                return True\n        return False\n\nclass Camera:\n    def __init__(self, p0, d):\n        self.d = d/np.dot(d, d)\n        self.p0 = p0\n\nclass Viewport:\n    def __init__(self, w, h, fov):\n        self.a = w/h\n        self.x = self.a*math.tan(fov/2)\n        self.y = math.tan(fov/2)\n        self.z = -1\n\nclass Canvas:\n    def __init__(self, w, h):\n        self.w = w\n        self.h = h\n        self.z_buffer = np.ones((w, h)) * Z_BUFFER_MAX\n        \n        \n\nclass Scene:\n    def __init__(self, camera, viewport, canvas):\n        # Camera obj\n        self.camera = camera\n        # viewport = Viewport obj\n        self.viewport = viewport\n        # canvas = Canvas obj\n        self.canvas = canvas\n        # self.lights = lights\n\n    def canvasToViewport(self, cx, cy):\n        # Convert a point on the canvas to viewport units\n        vw = self.viewport.x\n        vh = self.viewport.y\n        cw = self.canvas.w\n        ch = self.canvas.h\n\n        vx = cx * vw/cw\n        vy = cy * vh/ch\n        vz = viewport.z\n\n        return [vx, vy, vz]\n\n    def viewportToCanvas(self, vx, vy):\n        vw = self.viewport.x\n        vh = self.viewport.y\n        cw = self.canvas.w\n        ch = self.canvas.h\n        \n        cx = vx*cw/vw\n        cy = vy*ch/vh\n        \n        return cx, cy\n    \ndef biLerp(x, y, x1, y1, img):\n    x2, y2 = x1+1, y1+1\n    \n    q11 = (x1, y1)\n    q12= (x1, y2)\n    q21 = (x2, y1)\n    q22 = (x2, y2)\n    \n    c11 = np.array(img.getpixel(q11))\n    c12 = np.array(img.getpixel(q12))\n    c21 = np.array(img.getpixel(q21))\n    c22 = np.array(img.getpixel(q22))\n    \n    xd = x2-x1\n    x2d = x2-x\n    xd1 = x-x1\n    f01 = (x2d/xd)*c11 + (xd1/xd)*c21\n    f02 = (x2d/xd)*c12 + (xd1/xd)*c22\n    \n    yd = y2-y1\n    y2d = y2-y\n    yd1 = y-y1 \n    \n    f00 = (y2d/yd)*f01 + (yd1/yd)*f02\n    \n    return f00\n\ndef textureLookup(img, alpha, beta, gamma, t, z):\n    uv = (alpha*t[0]) + (beta*t[1]) + (gamma*t[2]) \n    overz = (alpha/z[0]) + (beta/z[1]) + (gamma/z[2])\n    uvz = 1/overz\n    uv *= uvz\n\n    img_res = img.size\n    x = uv[0] * (img_res[0]-1)\n    y = uv[1] * (img_res[1]-1)\n    \n    xt = math.floor(x)\n    yt = math.floor(y)\n    \n    rgb = biLerp(x,y,xt,yt, img)\n    \n    return rgb\n",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0d6a18ebe1de42eabd39fd91e34edef1",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2f36b7ea",
    "execution_start": 1650752510399,
    "execution_millis": 41,
    "owner_user_id": "1955af80-f317-4421-8653-9c485f9b411c",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1809
   },
   "source": "# Render function stolen from Kevin's HW ty \nZ_BUFFER_MAX = np.inf\nfov = 120\nimg_size = 512\nskip_triangles = 2 # Render faster\n\nobj_file = \"teapot.json\"\ntexture_file = \"jupiter.png\"\n\nambient_light_data = {'id': 'L1', \n                      'type': 'ambient', \n                      'color': [1, 1, 1], \n                      'intensity': 0.2}\ndirectional_light_data = {'type': 'directional',\n                          'color': [1, 0.5, 1],\n                          'intensity': 1.0,\n                          'from': [0, 0, 0.1],\n                          'to': [0, 0, 0]}\ncamera_location = [0, 0, 0]\ncamera_direction = [0, 0, -1]\n\ncamera = Camera(camera_location, camera_direction)\nviewport = Viewport(img_size, img_size, fov*math.pi/180)\ncanvas = Canvas(img_size, img_size)\n\nscene = Scene(camera, viewport, canvas)\n# texture_map = Image.open(texture_file).convert('RGB')\namb_source = LightSource(ambient_light_data['color'], ambient_light_data['intensity'], \"ambient\")\ndir_source = LightSource(directional_light_data['color'], directional_light_data['intensity'], \"directional\", directional_light_data[\"from\"])\nlm = Lighting(camera, amb_source, dir_source)\ntm = RenderTransforms()\n\nraytracer = RayTracer(obj_file, scene, lm, tm)\n\ndef render(json_file, save_img=0):\n    with open(json_file) as jf:\n        data = json.load(jf)\n    triangles = data['data']\n    material = {'Cs': [0, 1, 0], 'Ka': 0.35, 'Kd': 0.5, 'Ks': 0.9, 'n': 5.0}\n    \n    img = Image.new('RGB', (canvas.w, canvas.h), 0x0A834E)\n\n    triangle = {'v0': {'v': [1.4, 2.25, 0.0],\n            'n': [-0.902861, -0.429934, 0.0],\n            't': [0.0, 0.0]},\n           'v1': {'v': [1.2915, 2.25, 0.5495],\n            'n': [-0.833024, -0.43081, -0.347093],\n            't': [0.25, 0.0]},\n           'v2': {'v': [1.273482, 2.323828, 0.541834],\n            'n': [-0.918898, 0.095044, -0.382874],\n            't': [0.25, 0.25]}}\n    \n    transforms = [{'Rx': 0, 'Ry': 0, 'Rz': 0},\n                  {'S': [1, 1, 1]},\n                  {'T': [0, 0, -5]}]\n    \n    triangle = {\"v0\": {\"v\": [-1, -1, 0],\n                      \"n\":[0, 0, 1]}, \n                \"v1\": {\"v\": [-1, 1, 0],\n                      \"n\":[0, 0, 1]}, \n                \"v2\": {\"v\": [1, 0, 0],\n                      \"n\":[0, 0, 1]}\n               }\n    \n    tm.composeM(transforms)\n    for v in [\"v0\", \"v1\", \"v2\"]: triangle[v][\"v\"] = list(tm.RST(triangle[v][\"v\"]))[:3]\n    n = np.array([triangle[v]['n'] for v in ['v0', 'v1', 'v2']])\n\n    \n    for i, vx in enumerate(np.linspace(-viewport.x, viewport.x, 512)):\n        for j, vy in enumerate(np.linspace(-viewport.y, viewport.y, 512)):\n            for triangle in triangles[::skip_triangles]:\n\n                for v in [\"v0\", \"v1\", \"v2\"]: triangle[v][\"v\"] = list(tm.RST(triangle[v][\"v\"]))[:3]\n\n                z = [triangle[v]['v'][2] for v in [\"v0\", \"v1\", \"v2\"]]\n                t = [np.array(triangle[vz[0]]['t'])/vz[1] for vz in [('v0', z[0]), ('v1', z[1]), ('v2', z[2])]]\n                n = np.array([triangle[v]['n'] for v in ['v0', 'v1', 'v2']])\n\n                if min(z) < canvas.z_buffer[i, j]:       \n                    d = [vx, vy, viewport.z]\n                    raytracer.set_ray(d)\n\n                    t = raytracer.get_intersect(triangle)\n                    if t>0 and raytracer.inTriangle() and raytracer.intersect_point[2] < canvas.z_buffer[i, j]:\n                        canvas.z_buffer[i, j] = raytracer.intersect_point[2]\n                        alpha, beta, gamma = raytracer.alpha, raytracer.beta, raytracer.gamma\n\n    #                     color = textureLookup(texture_map, alpha, beta, gamma, t, z)\n    #                         shadow = raytracer.castShadowRay(dir_source, tm, triangles)\n    #                         if not shadow:\n                        n_interp = (alpha*n[0]) + (beta*n[1]) + (gamma*n[2])\n                        ads = lm.calculateADS(t, n_interp, material)\n                        rgb = (np.array(ads)* np.array([255, 0, 0])).astype(int)\n\n                        img.putpixel((i, j), tuple(rgb))\n    return img",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "44974ae3f93b46809eca31663c274104",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b766de4d",
    "execution_start": 1650752510860,
    "execution_millis": 523129,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 583.484375,
    "deepnote_output_heights": [
     424.296875
    ]
   },
   "source": "render(\"teapot.json\")",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f9256a9da198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"teapot.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-196fb1508910>\u001b[0m in \u001b[0;36mrender\u001b[0;34m(json_file, save_img)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mraytracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraytracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_intersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraytracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minTriangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraytracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                         \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraytracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-138aba27a6b3>\u001b[0m in \u001b[0;36mget_intersect\u001b[0;34m(self, triangle)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Get cross product of vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "2b5444136cdb43dcabf3847fc44b1dfd",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "43c49c11",
    "execution_start": 1650663498767,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 927
   },
   "source": "class RayTracer: \n    def __init__(self):\n        self.none = None\n        \n    def aFunction(self):\n        return 0\n    \n    def get_intersect(self, ray, v0, v1, v2):\n        # Calculate vectors\n        self.v0, self.v1, self.v2 = np.array(v0), np.array(v1), np.array(v2)\n        v10 = v1 - v0\n        v20 = v2 - v0\n        \n        # Get cross product of vectors \n        n = np.cross(v10, v20)\n        self.n = n / np.sqrt(np.dot(n, n))\n        \n        self.intersect = -(np.dot(self.n, ray.p0) + ray.d)/np.dot(self.n, ray.d)\n        return self.intersect\n    \n    def inTriangle(self):\n        # The normals for all 3 planes can be encoded in the identity matrix\n        plane_normals = np.identity(3)\n        # Check for planes perpendicular to the triangle\n        planes = np.matmul(plane_normals, self.n)\n        # Placeholder\n        projected_plane = 0 \n        # Select a valid plane to project to\n        for i in range(len(planes)): \n            if planes[i] != 0:\n                # Just leave loop once you found a valid plane\n                projected_plane = i\n                break\n        \n        # Projecting a point onto the x, y, or z plane can be thought of as just \n        # setting, x=0, y=0, or z=0 respectively\n        a,b = np.delete(self.intersect, projected_plane)\n        a0,b0 = np.delete(self.v0, projected_plane)\n        a1,b1 = np.delete(self.v1, projected_plane)\n        a2,b2 = np.delete(self.v2, projected_plane)\n        \n        # Calculate Barycentric Coordinates\n        alpha = f12(a,b,a0,b0,a1,b1,a2,b2)\n        beta  = f20(a,b,a0,b0,a1,b1,a2,b2)\n        gamma = f01(a,b,a0,b0,a1,b1,a2,b2)\n        \n        if (self.alpha >= 0) and (self.beta >= 0) and (self.gamma >= 0): return True\n        return False",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-1d3ce4b1-9f4e-47bf-a433-e19636a699c6",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "c7918b5c",
    "execution_start": 1650663498771,
    "execution_millis": 5,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1071
   },
   "source": "# Lighting Model to get ADS \nclass Lighting:\n    def __init__(self,\n                 camera,\n                 light\n                ):\n        self.L = self.normalize(light[1]['from']) # TODO: include from-to explicitly incase data is different in future\n        self.V = self.normalize(camera['from'])\n        \n        # Ambient lighting parameters\n        self.aColor = np.array(light[0]['color'])\n        self.Ia = light[0]['intensity']\n        \n        # Directional lighting parameters\n        self.dColor = np.array(light[1]['color']) #Directional Color\n        self.Ie = light[1]['intensity']\n        \n    def calculateADS(self, n, material):\n        n = self.normalize(n)\n        # Cases that come up in shading...\n        if np.dot(n, self.L) < 0 and np.dot(n, self.V) < 0: n*=-1 # CASE 1: \n        elif np.dot(n, self.L) * np.dot(n, self.V) < 0: emissive = np.array([0,0,0])\n        \n        Ka, Kd, Ks = material['Ka'], material['Kd'], material['Ks']\n        S = material['n']\n        \n        a = self.ambient(Ka)\n        d = self.diffuse(Kd, n)\n        s = self.specular(Ks, n, S)\n        \n        return a+d+s\n            \n    def ambient(self, Ka):\n        return Ka * self.aColor * self.Ia\n    \n    def diffuse(self, Kd, n):\n        dotnl = np.dot(n, self.L)\n        dotnl = np.clip(dotnl, 0, 1)\n        return Kd * self.dColor * dotnl * self.Ie\n    \n    def specular(self, Ks, n, S):\n        r = self.reflectionVector(n)\n        \n        dotre = np.dot(r, self.V)\n        dotre = np.clip(dotre, 0, 1) # Clamp RE\n        dotre = dotre**S # Apply Shininess\n        return Ks * self.dColor * dotre * self.Ie\n    \n    def reflectionVector(self, n):\n        # Calculate Normalized Reflection Vector\n        r = 2*(np.dot(n, self.L))*n - self.L\n        return self.normalize(r)\n        \n    def normalize(self, pt): \n        l = math.sqrt(pt[0]**2 + pt[1]**2 + pt[2]**2)\n        return np.array([pt[0]/l, pt[1]/l, pt[2]/l])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "343e997d3f0e45f5b3c922a1c39118a2",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1650663498776,
    "execution_millis": 3,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4e998d505bac483c88a7bd668252ff3f",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1650663498828,
    "execution_millis": 6504259,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0348dea39cf24d64814f34d30676b84a",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1650663498829,
    "execution_millis": 6504259,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b1d9b2dc-0aa6-4b59-8bd7-0b3848a2d4a6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "deepnote_notebook_id": "16ed2630-7370-4485-9abd-cb8c8f772384",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}