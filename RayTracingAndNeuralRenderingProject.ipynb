{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d9da804b-38c4-426f-b8fd-0684d1971673",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "eeb6239",
    "execution_start": 1650517747959,
    "execution_millis": 1743,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585
   },
   "source": "import json\nimport numpy as np\nimport time\nfrom PIL import Image\nimport math\nimport matplotlib.pyplot as plt\nimport random\nimport uuid\nimport pandas as pd\n\ndef f01(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x0*y1)-(x1*y0)\n    u = y0-y1\n    v = x1-x0\n    \n    return ((u*x) + (v*y) + q)/((u*x2) + (v*y2) + q)\n\ndef f12(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x1*y2)-(x2*y1)\n    u = y1-y2\n    v = x2-x1\n    \n    return ((u*x) + (v*y) + q)/((u*x0) + (v*y0) + q)\n\ndef f20(x,y,x0,y0,x1,y1,x2,y2):\n    q = (x2*y0)-(x0*y2)\n    u = y2-y0\n    v = x0-x2\n    return ((u*x) + (v*y) + q)/((u*x1) + (v*y1) + q)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# RayTracer\nhttps://bytes.usc.edu/cs580/s22_CG-012-Ren/lectures/Lect_RT/GeomQueries/slides_intersections.html",
   "metadata": {
    "cell_id": "00001-05936431-f3ff-4bb0-8571-b1b4b3155b22",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 120.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1d23005ecb224de1a80441931219c1f9",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b245e244",
    "execution_start": 1650517754599,
    "execution_millis": 5,
    "owner_user_id": "1955af80-f317-4421-8653-9c485f9b411c",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 2511
   },
   "source": "# Miscellaneous:\n#  Determine image plane given camera @ (0,0,0) with a Field-of-View and how to \n#    convert the image plane into a pixelated image. \n#    Let Field-of-View = 120 deg (matching iPhone 13)\n#  Create surface plane to show shadows from ray-tracing\n#  Calculate sphere model (pending)\n \n\n# Direction: P2-P1 (128, 100, -1) - (0, 0, 0) = (128, 100, -1)\n# Normalize the above\nclass Ray:\n    def __init__(self, p0, d, t = -1):\n        # p0, origin of a Ray\n        self.p0 = p0 \n        self.d = d * (1 / np.linalg.norm(d)) \n        self.t = t\n        # d, unit vector, direction of ray (normalized)\n        # self.var = None\n    \n    def set_t(self, t):\n        self.t = t\n        \n    def get_point(self):\n        return np.add(self.p0, np.multiply(self.d, self.t))\n\nclass Plane:\n    def __init__(self, p0, normal):\n        self.p0 = p0 # point on the plane\n        self.normal = normal\n    \n    def on_plane(self, p1):\n        # Checks if point is on plane, not really useful but for reference\n        return (np.dot(normal, np.subtract(self.p0-p1)) == 0)\n\n\n# viewport of [1,1] and distance of 1 would make FOV 53 degrees\nclass RayTracer: \n    def __init__(self, scene, viewport, canvas):\n        # Load scene data for rendering\n        self.scene = scene\n        # List in format of {\"vw\": vw, \"vh\": vh, \"d\": d}, where vw = viewport width, vh = viewport height, d = distance from viewport\n        self.viewport = viewport\n        # Canvas info in format of {\"w\": w, \"h\": h}\n        self.canvas = canvas\n    \n    def canvasToViewport(self, cx, cy):\n        # Convert a point on the canvas to viewport units\n        vw = self.viewport.vw\n        vh = self.viewport.vh\n        cw = self.canvas.w\n        ch = self.canvas.h\n\n        vx = cx * vx/cw\n        vy = cy * vh/ch\n        vz = viewport.d\n\n        return [vx, vy, vz]\n        \n    \n    def get_intersect(self, ray, triangle_vertices, triangle_normal):\n        # Calculate if a ray intersects with a plane that contains a triangle\n        # Helps filter out unnecessary triangles and calculates important values\n        #    such as normals, and points of intersection.\n        # Returns t if it intersects and is in the triangle, -1 otherwise\n\n        v0 = triangle_vertices[\"v0\"]\n\n        cam_ray = Ray(self.scene[\"camera\"][\"point\"], self.scene[\"camera\"][\"direction\"])\n        plane = Plane(v0, triangle_normal)\n\n        # t = (n⋅(p⋅s))/(n⋅d) where \n        # p = point on plane\n        # s = ray start point\n        # d = camera direction\n        # n = plane normal\n\n        denominator = np.dot(n, d)\n\n        # Checks if camera ray is parallel to the plane, in which case the ray will never hit the plane\n        if denominator < 0.00001:\n            return -1\n\n        # Calculate t value, then plug into formula to get the point on the plane\n        t = np.dot(plane.normal, np.dot(plane.p0, cam_ray.p0)) / denominator \n\n        plane.set_t(t)\n        point_on_plane = plane.get_point()\n        \n        # Checks to see if the point is on the plane\n        if self.inTriangle(triangle_vertices, plane.normal, point_on_plane):\n            return point_on_plane\n\n        return -1\n    \n    # def inTriangle(self):\n    #     # Calculate if a ray intersect falls within a triangle\n    #     # Project vertices of triangle onto 2D plane then you can \n    #     # use barycentric coordinates like in the homework\n\n    def inTriangle(self, triangle_vertices, normal, point_on_plane):\n\n        # Check if in triangle not using barycentric coordinates (barycentric is better)\n\n        v0 = triangle_vertices[\"v0\"]\n        v1 = triangle_vertices[\"v1\"]\n        v2 = triangle_vertices[\"v2\"]\n\n        # Calculate the edge vectors\n        v0v1_edge = np.subtract(v1, v0)\n        v1v2_edge = np.subtract(v2, v1)\n        v2v0_edge = np.subtract(v0, v2)\n\n        # Get vectors from vert to point on plane\n        v0_point = np.subtract(point_on_plane, v0)\n        v1_point = np.subtract(point_on_plane, v1)\n        v2_point = np.subtract(point_on_plane, v2)\n        \n        # Get cross product and compare it to normal\n        v0_cross = np.cross(v0v1_edge, v0_point)\n        v1_cross = np.cross(v1v2_edge, v1_point)\n        v2_cross = np.cross(v2v0_edge, v2_point)\n        \n        # If the dot == 0, normal and cross product are opposite to each other, so it will not be in the plane\n        v0_normal_dot = np.dot(v0_cross, normal) > 0\n        v1_normal_dot = np.dot(v1_cross, normal) > 0\n        v2_normal_dot = np.dot(v2_cross, normal) > 0\n\n        return v0_normal_dot and v1_normal_dot and v2_normal_dot\n    \n    def castShadowRay(self):\n        # Attempt to trace shadow ray back to light source \n        # If hits another poylgon, color should be a shadow\n        # If shadow ray can be traced back to light source, calculate lighting to fill pixel\n        \n        \n        return",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-1d3ce4b1-9f4e-47bf-a433-e19636a699c6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c7918b5c",
    "execution_start": 1650513689819,
    "execution_millis": 7,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1071
   },
   "source": "# Lighting Model to get ADS \nclass Lighting:\n    def __init__(self,\n                 camera,\n                 light\n                ):\n        self.L = self.normalize(light[1]['from']) # TODO: include from-to explicitly incase data is different in future\n        self.V = self.normalize(camera['from'])\n        \n        # Ambient lighting parameters\n        self.aColor = np.array(light[0]['color'])\n        self.Ia = light[0]['intensity']\n        \n        # Directional lighting parameters\n        self.dColor = np.array(light[1]['color']) #Directional Color\n        self.Ie = light[1]['intensity']\n        \n    def calculateADS(self, n, material):\n        n = self.normalize(n)\n        # Cases that come up in shading...\n        if np.dot(n, self.L) < 0 and np.dot(n, self.V) < 0: n*=-1 # CASE 1: \n        elif np.dot(n, self.L) * np.dot(n, self.V) < 0: emissive = np.array([0,0,0])\n        \n        Ka, Kd, Ks = material['Ka'], material['Kd'], material['Ks']\n        S = material['n']\n        \n        a = self.ambient(Ka)\n        d = self.diffuse(Kd, n)\n        s = self.specular(Ks, n, S)\n        \n        return a+d+s\n            \n    def ambient(self, Ka):\n        return Ka * self.aColor * self.Ia\n    \n    def diffuse(self, Kd, n):\n        dotnl = np.dot(n, self.L)\n        dotnl = np.clip(dotnl, 0, 1)\n        return Kd * self.dColor * dotnl * self.Ie\n    \n    def specular(self, Ks, n, S):\n        r = self.reflectionVector(n)\n        \n        dotre = np.dot(r, self.V)\n        dotre = np.clip(dotre, 0, 1) # Clamp RE\n        dotre = dotre**S # Apply Shininess\n        return Ks * self.dColor * dotre * self.Ie\n    \n    def reflectionVector(self, n):\n        # Calculate Normalized Reflection Vector\n        r = 2*(np.dot(n, self.L))*n - self.L\n        return self.normalize(r)\n        \n    def normalize(self, pt): \n        l = math.sqrt(pt[0]**2 + pt[1]**2 + pt[2]**2)\n        return np.array([pt[0]/l, pt[1]/l, pt[2]/l])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b1d9b2dc-0aa6-4b59-8bd7-0b3848a2d4a6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "deepnote_notebook_id": "16ed2630-7370-4485-9abd-cb8c8f772384",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}